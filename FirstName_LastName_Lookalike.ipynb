{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec35ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ======================================================\n",
    "# 1. Load Data with Column Conflict Resolution\n",
    "# ======================================================\n",
    "# Load datasets with proper type casting\n",
    "customers = pd.read_csv(\"Customers.csv\", parse_dates=[\"SignupDate\"])\n",
    "products = pd.read_csv(\"Products.csv\").rename(columns={\"Price\": \"ProductPrice\"})\n",
    "transactions = pd.read_csv(\"Transactions.csv\", \n",
    "                          parse_dates=[\"TransactionDate\"],\n",
    "                          dtype={'CustomerID': 'string'})\n",
    "\n",
    "# Merge datasets\n",
    "merged_data = (\n",
    "    transactions\n",
    "    .merge(products, on=\"ProductID\")\n",
    "    .merge(customers, on=\"CustomerID\")\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 2. Feature Engineering (Enhanced)\n",
    "# ======================================================\n",
    "# Calculate days since last transaction\n",
    "snapshot_date = pd.Timestamp.now()\n",
    "\n",
    "customer_features = merged_data.groupby('CustomerID').agg({\n",
    "    'TotalValue': ['sum', 'mean'],\n",
    "    'TransactionID': 'count',\n",
    "    'TransactionDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'Region': 'first',\n",
    "    'Category': lambda x: x.value_counts().index[0] if not x.empty else 'Unknown'\n",
    "}).reset_index()\n",
    "\n",
    "# Clean column names\n",
    "customer_features.columns = [\n",
    "    'CustomerID', 'TotalSpent', 'AvgSpent', \n",
    "    'Frequency', 'Recency', 'Region', 'FavoriteCategory'\n",
    "]\n",
    "\n",
    "customer_features.to_csv(\"customer_features.csv\", index=False)\n",
    "\n",
    "# ======================================================\n",
    "# 3. Data Preprocessing Pipeline\n",
    "# ======================================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Region', 'FavoriteCategory']),\n",
    "        ('num', StandardScaler(), ['TotalSpent', 'AvgSpent', 'Frequency', 'Recency'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "processed_features = preprocessor.fit_transform(\n",
    "    customer_features.drop('CustomerID', axis=1)\n",
    ")\n",
    "\n",
    "# Manually construct column names for older scikit-learn versions\n",
    "cat_transformer = preprocessor.named_transformers_['cat']\n",
    "num_features = ['TotalSpent', 'AvgSpent', 'Frequency', 'Recency']\n",
    "\n",
    "# Get OneHotEncoder-generated column names\n",
    "cat_features = cat_transformer.get_feature_names(['Region', 'FavoriteCategory'])\n",
    "\n",
    "# Combine all column names\n",
    "all_columns = np.concatenate([cat_features, num_features])\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "processed_df = pd.DataFrame(processed_features, columns=all_columns)\n",
    "processed_df.to_csv('processed_features.csv', index=False)\n",
    "\n",
    "# ======================================================\n",
    "# 4. Similarity Model (Optimized)\n",
    "# ======================================================\n",
    "model = NearestNeighbors(n_neighbors=4, metric='cosine')\n",
    "model.fit(processed_features)\n",
    "\n",
    "# ======================================================\n",
    "# 5. Generate Recommendations (With Error Handling)\n",
    "# ======================================================\n",
    "lookalikes = {}\n",
    "target_customers = [f\"C00{i:02d}\" for i in range(1, 21)]\n",
    "\n",
    "for cust_id in target_customers:\n",
    "    try:\n",
    "        # Check if customer exists in the data\n",
    "        mask = customer_features['CustomerID'] == cust_id\n",
    "        if not mask.any():\n",
    "            print(f\"Customer {cust_id} not found - skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Find the index of the target customer in the processed features\n",
    "        idx = customer_features[mask].index[0]\n",
    "        distances, indices = model.kneighbors(processed_features[idx:idx+1])\n",
    "\n",
    "        recommendations = []\n",
    "        for neighbor_idx, distance in zip(indices[0][1:], distances[0][1:]):  # Skip self\n",
    "            neighbor_id = customer_features.iloc[neighbor_idx]['CustomerID']\n",
    "            similarity = 1 - distance\n",
    "            recommendations.append((neighbor_id, round(similarity, 2)))\n",
    "        \n",
    "        lookalikes[cust_id] = recommendations\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cust_id}: {str(e)}\")\n",
    "\n",
    "# ======================================================\n",
    "# 6. Save Results (Required Format)\n",
    "# ======================================================\n",
    "# Create formatted CSV\n",
    "output_rows = []\n",
    "for cust_id in target_customers:\n",
    "    if cust_id not in lookalikes:\n",
    "        output_rows.append([cust_id, None, None, None, None, None, None])\n",
    "        continue\n",
    "    \n",
    "    recs = lookalikes[cust_id]\n",
    "    row = [cust_id]\n",
    "    for rec in recs:\n",
    "        row.extend(rec)\n",
    "    \n",
    "    # Fill empty slots if <3 recommendations\n",
    "    while len(row) < 7:  # 1 ID + 3*(ID+score) = 7 elements\n",
    "        row.extend([None, None])\n",
    "    \n",
    "    output_rows.append(row)\n",
    "\n",
    "result_df = pd.DataFrame(output_rows, columns=[\n",
    "    'CustomerID',\n",
    "    'Lookalike1', 'Score1',\n",
    "    'Lookalike2', 'Score2', \n",
    "    'Lookalike3', 'Score3'\n",
    "])\n",
    "\n",
    "result_df.to_csv(\"Lookalike.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f544bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
